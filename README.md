# Depression-Detection-using-Speech
Though the social media provides a means to capture an individual’s present state of mind, but sometimes a person’s feeling or thoughts might depend on one or other indirect causes and thus this data can’t solely be used for depression detection. Therefore, we extended our approach by further analysing the audio features of each individual being interviewed by a virtual interviewer called Ellie, controlled by a human interviewer in another room. Each of the session lasted for an average of 16 minutes. Also, prior to the interview, each participant completed a psychiatric questionnaire (PHQ-8) [5], from which a binary "truth" classification (depressed, not depressed) was derived. It was implemented in following phases:

•	Data Collection: The data collected include audio and video recordings and extensive questionnaire responses. Data has been transcribed and annotated for a variety of verbal and non-verbal features. All audio recordings and associated depression metrics were provided by the DAIC-WOZ Database [9], which was compiled by USC's Institute of Creative Technologies and released as part of the 2016 Audio/Visual Emotional Challenge and Workshop (AVEC 2016). The dataset consists of 189 sessions. The audio data provided by AVEC consisted of an audio file of entire interview with the participant, pre-extracted features using the COVAREP toolbox at 10-ms intervals over the entire recording (F0, NAQ, QOQ, H1H2, PSP, MDQ, peak Slope, Rd, Rd conf, MCEP 0-24, HMPDM 1-24, HMPDD 1-12, and Formants 1-3), Transcript file containing speaking times and values of participant and the virtual interviewer, and a formant file.

•	Data Pre-processing: Data pre-processing has been done for removing the rows that are having 50% or more of the values as zeroes as it is of no use. Further, PHQ-8 score column is added in each of the files for training of the model. 

•	Handling Large Data: Data has been divided into 11 separate folders for training purpose. Each folder is separately trained on the model and overall results are averaged for testing purpose. Only 10 percent of the data has been utilised for training purposes which was randomly selected from the data of every patient. Also, the data types of data are reduced from 64- bit float to 32-bit float. After training every model data frame are removed to evacuate the space so that enough space is available on RAM for the training purpose of each of the folders generated.

•	Data Imbalance: Data pre-processing has been done for removing the rows with having 50% or more of the values as zeroes as it is of no use. Further,189 sessions of interactions were ranging between 7-33min (with an average of 16min) therefore, biasing can occur. Also, a larger volume of signal from an individual may emphasize some characteristics that may be specific to a person. In the data-set, the number of non-depressed subjects is about four times larger than that of depressed ones. To rectify this imbalance, undersampling has been done on the dataset.

Data Correlation: Correlation matrix is generated to identify the relationship between the different audio features and how they can impact each other. The correlation coefficient values obtained lies between 0 and 0.4 (Fig-6.7). This indicates that features are independent of each other. Further, the impact of each of the features on the target variable of score prediction is also analysed (Fig. 6.8).

•	Classification: Using Support Vector Regression (kernel-sigmoid), Support Vector Regressor with (kernel linear), Random Forest Regressor with 40 estimators and Random Forest Regressor with 400 estimators, for predicting the PHQ-8 score of the tested participants against the proposed model. Further, for analysing the accuracy of the model the hypothesis is considered that person with depression scale value>=10 is depressed and otherwise not depressed. The binary classification column is added addressing the depressed person as “1”.The measure of how well the model performs was taken as the similarity in results of the model implemented and the questionnaire. If majority of the answers in the questionnaire in a domain were marked” yes” and the model too gave a higher value for that category, then the case was taken as positives. Any conflict resulted in a negative case. The models have been evaluated by measuring the root mean square error and mean absolute error when predicting the PHQ8 score of a patient


MODEL	Accuracy	MAE(Mean Absolute Error)	RMSE(Root Mean Square Error)
SVR with Linear kernel	71.8%	5.403	5.434
SVR with Sigmoid Kernel	71.8%	5.394	5.413
Random Forest 40	71.8%	6.2117	6.2514
Random Forest 400	71.8%	6.233	6.274

